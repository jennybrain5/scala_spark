{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL using Scala and Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.11:4042\n",
       "SparkContext available as 'sc' (version = 3.0.0, master = local[*], app id = local-1595592847834)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "bat_datos: org.apache.spark.sql.DataFrame = [vcd: string, amp: string ... 4 more fields]\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bat_datos = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").load(\"data/baterias-datos.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+-----+---------+------+\n",
      "|  vcd|  amp|  tmp|  imp|estado_id|estado|\n",
      "+-----+-----+-----+-----+---------+------+\n",
      "|14,30|68,52|13,83|39,19|        0|    ok|\n",
      "|14,48|86,92|12,75|32,74|        0|    ok|\n",
      "|14,18|80,65| 5,27|27,58|        0|    ok|\n",
      "|13,68|56,30|13,96|17,91|        0|    ok|\n",
      "|13,67|61,49| 7,71|26,40|        0|    ok|\n",
      "|14,50|72,96|18,06|34,24|        0|    ok|\n",
      "|14,33|85,43| 8,97|30,19|        0|    ok|\n",
      "|14,18|55,65|14,16|34,74|        0|    ok|\n",
      "|14,06|58,50|10,04|29,77|        0|    ok|\n",
      "|14,28|59,43| 6,42|11,85|        0|    ok|\n",
      "|14,47|79,23| 8,83|24,78|        0|    ok|\n",
      "|13,83|89,96|10,35|14,94|        0|    ok|\n",
      "|13,94|63,25|13,54|23,35|        0|    ok|\n",
      "|13,91|64,80|17,63|24,68|        0|    ok|\n",
      "|14,24|64,82|17,59|15,99|        0|    ok|\n",
      "|14,43|70,65|24,36|22,19|        0|    ok|\n",
      "|13,93|85,23|18,37|28,60|        0|    ok|\n",
      "|14,01|79,98|10,49|29,21|        0|    ok|\n",
      "|14,03|55,24|19,24|17,94|        0|    ok|\n",
      "|14,14|61,81|15,11|30,77|        0|    ok|\n",
      "+-----+-----+-----+-----+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bat_datos.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print data frame schema. All variables all string type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595\n",
      "root\n",
      " |-- vcd: string (nullable = true)\n",
      " |-- amp: string (nullable = true)\n",
      " |-- tmp: string (nullable = true)\n",
      " |-- imp: string (nullable = true)\n",
      " |-- estado_id: string (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(bat_datos.count())\n",
    "bat_datos.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform data types from string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vcd: float (nullable = true)\n",
      " |-- amp: float (nullable = true)\n",
      " |-- tmp: float (nullable = true)\n",
      " |-- imp: float (nullable = true)\n",
      " |-- estado_id: integer (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.DoubleType\r\n",
       "import org.apache.spark.sql.types.IntegerType\r\n",
       "import org.apache.spark.sql.types.FloatType\r\n",
       "df_datos: org.apache.spark.sql.DataFrame = [vcd: float, amp: float ... 4 more fields]\r\n",
       "df_datos: org.apache.spark.sql.DataFrame = [vcd: float, amp: float ... 4 more fields]\r\n",
       "df_datos: org.apache.spark.sql.DataFrame = [vcd: float, amp: float ... 4 more fields]\r\n",
       "df_datos: org.apache.spark.sql.DataFrame = [vcd: float, amp: float ... 4 more fields]\r\n",
       "df_datos: org.apache.spark.sql.DataFrame = [vcd: float, amp: float ... 4 more fields]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.DoubleType;\n",
    "import org.apache.spark.sql.types.IntegerType;\n",
    "import org.apache.spark.sql.types.FloatType;\n",
    "\n",
    "var df_datos = bat_datos.withColumn(\"estado_id\", $\"estado_id\".cast(IntegerType))\n",
    "\n",
    "df_datos = df_datos.withColumn(\"vcd\", regexp_replace($\"vcd\", \",\", \".\").cast(\"float\"))\n",
    "df_datos = df_datos.withColumn(\"amp\", regexp_replace($\"vcd\", \",\", \".\").cast(\"float\"))\n",
    "df_datos = df_datos.withColumn(\"tmp\", regexp_replace($\"vcd\", \",\", \".\").cast(\"float\"))\n",
    "df_datos = df_datos.withColumn(\"imp\", regexp_replace($\"vcd\", \",\", \".\").cast(\"float\"))\n",
    "\n",
    "df_datos.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter data by \"estado_id\", print result data frame and number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+\n",
      "|  amp|  tmp|estado|\n",
      "+-----+-----+------+\n",
      "| 13.1| 13.1|alerta|\n",
      "|13.38|13.38|alerta|\n",
      "|13.28|13.28|alerta|\n",
      "|13.32|13.32|alerta|\n",
      "|13.27|13.27|alerta|\n",
      "|13.33|13.33|alerta|\n",
      "|13.39|13.39|alerta|\n",
      "|13.13|13.13|alerta|\n",
      "|13.26|13.26|alerta|\n",
      "| 13.1| 13.1|alerta|\n",
      "|13.38|13.38|alerta|\n",
      "|13.07|13.07|alerta|\n",
      "|13.45|13.45|alerta|\n",
      "|13.37|13.37|alerta|\n",
      "|13.01|13.01|alerta|\n",
      "|13.26|13.26|alerta|\n",
      "|13.24|13.24|alerta|\n",
      "|13.04|13.04|alerta|\n",
      "|13.35|13.35|alerta|\n",
      "|13.33|13.33|alerta|\n",
      "+-----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Registros: 200"
     ]
    },
    {
     "data": {
      "text/plain": [
       "new_df: org.apache.spark.sql.DataFrame = [amp: float, tmp: float ... 1 more field]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var new_df=df_datos.filter(\n",
    "    $\"estado_id\" === 1\n",
    ").select(\n",
    "    $\"amp\",\n",
    "    $\"tmp\",\n",
    "    $\"estado\"\n",
    ")\n",
    "\n",
    "new_df.show()\n",
    "print(\"Registros: \"+new_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
